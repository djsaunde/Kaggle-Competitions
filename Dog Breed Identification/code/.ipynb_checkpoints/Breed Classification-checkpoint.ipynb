{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Identification (Part II): Breed Classification\n",
    "\n",
    "We continue with our efforts on the [Dog Breed Identification Kaggle Competition](https://www.kaggle.com/c/dog-breed-identification). This time, we'll focus on building a deep __convolutional neural network__ to model the function between input images, $\\{ \\mathbf{X}^{(i)} \\}_{i = 1}^{N_{\\textrm{train}}}$, and corresponding labels, $\\{ y^{(i)} \\}_{i = 1}^{N_{\\textrm{train}}}$, where $N_{\\textrm{train}}$ = the number of _training data_ available. The labels $y^{(i)} \\in \\{ 1, ..., K \\}$ are proxy to the _object category_ of the input $\\mathbf{X}^{(i)}$; e.g., if some $\\mathbf{X}^{(i)}$ is an image containing an [Alaskan Malamute](https://en.wikipedia.org/wiki/Alaskan_Malamute), its label should be the integer which is mapped to the category \"Alaskan Malamute\". All possible object categories have a corresponding integer label.\n",
    "\n",
    "We also have access to a (smaller) _validation dataset_, which we periodically evaluate our network on to ensure we don't [overfit](https://en.wikipedia.org/wiki/Overfitting) the training data. We denote the validation data as $(\\{ \\mathbf{X}^{(i)}, y^{(i)} \\})_{i = 1}^{N_{\\textrm{validate}}}$, where $N_{\\textrm{validate}}$ = the number of _validation data_ available, and $N_{\\textrm{validate}} << N_{\\textrm{train}}$.\n",
    "\n",
    "A neural network can be expressed as a parametric function $f(\\mathbf{X}^{(i)}; \\theta)$; parametrized by a _parameter vector_ $\\theta$. The parameters correspond to the __learned weights__ on the connections between neurons of adjacent layers. The goal is to learn a setting of $\\theta$ which minimizes the differences between $\\sum_{i = 1}^{N_{\\textrm{train}}} \\left[ f(\\mathbf{X}^{(i)}; \\theta) - y^{(i)} \\right]$, while simultaneously choosing a reasonable setting of parameters that we expect to generalize well to new (e.g., test) data.\n",
    "\n",
    "For the Kaggle competition, we are given _test data_ $\\{ \\mathbf{X}^{(i)} \\}_{i = 1}^{N_{\\textrm{test}}}$, and we submit $\\{ f(\\mathbf{X}^{(i)}; \\hat{\\theta}^*) = \\hat{y}^{(i)} \\}_{i = 1}^{N_{\\textrm{test}}}$, where $\\hat{\\theta}^*$ is an estimate of optimal parameters given the particular neural network model. These __predictions__ (or __inferences__) will be compared with the [ground truth](https://en.wikipedia.org/wiki/Ground_truth) categorical labels, and we will be ranked according to the number of test data our model misclassified.\n",
    "\n",
    "At the time of writing, the best __error rate__ listed on the competition's leaderboard is 0.313% (accuracy of 100% - 0.313% = 99.687%). We don't expect to beat this, but obtaining a model with ~2-3% error rate is a realistic and challenging goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports / miscellany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_path = os.path.join('..', 'data', 'processed_train')\n",
    "valid_path = os.path.join('..', 'data', 'processed_valid')\n",
    "test_path = os.path.join('..', 'data', 'processed_test')\n",
    "\n",
    "# Are there CUDA-enabled GPU devices available? \n",
    "cuda = torch.cuda.device_count() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed doggos\n",
    "\n",
    "We've already pre-processed the pupper image data. For now, we will simply load it into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Custom torch.utils.Dataset used for reading\n",
    "    in a list of data files from disk.\n",
    "    '''\n",
    "    def __init__(self, data_path):\n",
    "        self.data_files = os.listdir(data_path)\n",
    "        self.data_path = data_path\n",
    "        sorted(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        (X_batch, y_batch) = np.load(os.path.join(self.data_path, self.data_files[idx]))\n",
    "        return torch.from_numpy(X_batch).float(), torch.from_numpy(y_batch).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training (input, target) data.\n",
    "train_data = ListDataset(train_path)\n",
    "\n",
    "# Load validation (input, target) data.\n",
    "valid_data = ListDataset(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training data: 8177\n",
      "No. of validation data: 2045\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: print out training, validation data shapes\n",
    "print('No. of training data:', len(train_data))\n",
    "print('No. of validation data:', len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PyTorch neural network model\n",
    "\n",
    "Here is where things get interesting. We will use the [PyTorch deep learning library](http://pytorch.org/) (which I highly recommend!) to create a convolutional neural network (CNN) to learn an approximate mapping between inputs $\\mathbf{X}$ and targets $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    '''\n",
    "    Defines the convolutional neural network model.\n",
    "    '''\n",
    "    def __init__(self, input_size, n_classes):\n",
    "        '''\n",
    "        Constructor for the CNN object.\n",
    "        \n",
    "        Arguments:\n",
    "            - input_size (int): The number of units in the input \"layer\".\n",
    "                Corresponds to the number of pixels in the input images.\n",
    "            - n_classes (int): The number of target categories in the data.\n",
    "        \n",
    "        Returns:\n",
    "            - Instantiated CNN object.\n",
    "        '''\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layer portion of the network.\n",
    "        self.convolutional = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, \\\n",
    "                    kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, \\\n",
    "                    kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, \\\n",
    "                    kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, \\\n",
    "                    kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, \\\n",
    "                    kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, \\\n",
    "                    kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # Fully-connected layer portion of the network.\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the forward pass of the network.\n",
    "        \n",
    "        Arguments:\n",
    "            - x (np.ndarray): A minibatch of images with\n",
    "                shape (M, D, H, W), with M = minibatch size.\n",
    "        \n",
    "        Returns:\n",
    "            - Activations of the final layer of the CNN. That is,\n",
    "                the representation of the input, learned by the network,\n",
    "                which is used to disentangle the correct object category.\n",
    "        '''\n",
    "        # Get features computed by convolutional portion of the network.\n",
    "        conv_features = self.convolutional(x)\n",
    "        \n",
    "        # Flatten these features from 4D (batch_size, D, H, W)\n",
    "        # tensor to 2D (batch_size, D * H * W) tensor.\n",
    "        flat_features = conv_features.view(conv_features.size(0), -1)\n",
    "                \n",
    "        # Get prediction computed by the fully-connected portion of the network.\n",
    "        predictions = self.dense(flat_features)\n",
    "        \n",
    "        # Return the processed input data as the predicted target values.\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the network, we can instantiate one and train it to identify the dog breeds in our image dataset. But first, we must choose network [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) (parameters that are chosen prior to training which affect how the training operates, as opposed to parameters which are learned during network training). We also store some useful information in workspace-level variables, which can be changed once (here) to affect the rest of the notebook. Finally, we will use `torch.utils.data.DataLoader`s to simplify the presentation of data to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 50  # No. of times to train on the entire training data.\n",
    "batch_size = 100  # No. of examples used in minibatch stochastic gradient descent (SGD).\n",
    "print_interval = 10  # No. of minibatch SGD iterations between each progress message.\n",
    "\n",
    "# Useful information\n",
    "input_size = (256, 256)  # As defined in \"Data Exploration.ipynb\".\n",
    "n_classes = 120  # No. of doggo breeds.\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the doggo recognizer\n",
    "\n",
    "We're ready to begin network training. We'll instantiate a network, define the criterion we aim to minimize ([Multiclass Log Loss](https://www.kaggle.com/wiki/MultiClassLogLoss)), define the optimization algorithm (we'll use [Adam](https://arxiv.org/abs/1412.6980), short for adaptive moments, a variant of SGD which dynamically updates individual parameter learning rates during training), and train the model for some number of epochs (the number of passes through the training data, given by `n_epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate CNN object.\n",
    "network = CNN(input_size=input_size, n_classes=n_classes)\n",
    "if cuda:\n",
    "    network.cuda()\n",
    "\n",
    "# Create loss / cost /objective function.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify optimization routine.\n",
    "optimizer = torch.optim.Adam(network.parameters(), weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> <class 'torch.FloatTensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Need input.size[1] == 3 but got 256 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-061f94bcd95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Run forward pass of network to get predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Get integer predictions by selecting the maximal output activation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-e5ea21f6b856>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m         '''\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Get features computed by convolutional portion of the network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mconv_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Flatten these features from 4D (batch_size, D, H, W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 254\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     50\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     51\u001b[0m                _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Need input.size[1] == 3 but got 256 instead."
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train_correct, train_total = 0, 0\n",
    "    \n",
    "    # On each minibatch SGD iteration, we get `batch_size` samples from `X_train`.\n",
    "    for idx, (inputs, targets) in enumerate(train_loader):\n",
    "        print(type(inputs), type(targets))\n",
    "        # Convert `torch.Tensor`s to `Variable`s.\n",
    "        if cuda:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            targets = Variable(targets.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "            targets = Variable(targets)\n",
    "        \n",
    "        # Run forward, backward pass of network.\n",
    "        # Zero out gradient buffer.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Run forward pass of network to get predictions.\n",
    "        predictions = network.forward(inputs)\n",
    "        \n",
    "        # Get integer predictions by selecting the maximal output activation.\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        \n",
    "        # Add correct classifications to a running sum.\n",
    "        train_correct += (predicted.cpu() == targets.data.cpu()).sum()\n",
    "        \n",
    "        # Add number of items in the minibatch to running sum.\n",
    "        train_total += targets.size(0)\n",
    "        \n",
    "        # Calculate loss (non-negative function of predictions and true targets).\n",
    "        loss = criterion(predictions, targets)\n",
    "        \n",
    "        # Run backward pass (calculate gradient of loss w.r.t. network parameters).\n",
    "        loss.backward()\n",
    "        \n",
    "        # Take optimization step (update network parameters in opposite direction of loss).\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % print_interval == 0:\n",
    "            print('Epoch [%d / %d], Iteration [%d / %d], Loss: %.4f' % (epoch + 1, \\\n",
    "                                n_epochs, idx + 1, len(train_loader), loss.data[0]))\n",
    "    \n",
    "    valid_correct, valid_total = 0, 0\n",
    "    \n",
    "    # Calculate the accuracy of the network on the\n",
    "    # validation data at the end of each epoch.\n",
    "    for idx, (inputs, targets) in enumerate(valid_loader):\n",
    "        # Convert `torch.Tensor`s to `Variable`s.\n",
    "        if cuda:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        \n",
    "        predictions = network.forward(inputs)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        valid_correct += (predicted.cpu() == targets).sum()\n",
    "        \n",
    "        valid_total += targets.size(0)\n",
    "        \n",
    "    print()\n",
    "    print('Training accuracy: %.4f' % (100 * train_correct / train_total))\n",
    "    print('Validation accuracy: %.4f' % (100 * valid_correct / valid_total))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
