{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits Recognizer Kaggle Competition\n",
    "\n",
    "I'll use a convolutional neural network to classify the handwritten digits dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Python software packages we use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from random import choice\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Change these to determine the hyperparameter configuration of the convolutional neural network and the data-preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determines training / validation split\n",
    "TRAIN_SIZE = 37000\n",
    "\n",
    "# neural network learning rate\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# minibatch size\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# dropout probability\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# number of training epochs\n",
    "EPOCHS = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "The training dataset has 42,000 rows and 784 columns, where each row corresponds to a single image of a digit, and each column corresponds to the value of a pixel intensity in an image of a digit; i.e., each column is a \"feature\" of the digit representation. The test dataset has some 28,000 rows and again, 784 columns. \n",
    "\n",
    "The datapoints have been flattened from shape (28, 28) to (784,), which makes things easier to process using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in training data\n",
    "train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shapes: (37000, 784) (37000, 10)\n",
      "validation data shapes: (5000, 784) (5000, 10)\n",
      "test data shape:"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3a800d1c41b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'training data shapes:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'validation data shapes:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'test data shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# get size, shape of dataset images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# store training dataset as NumPy arrays\n",
    "X_train = np.array(train.drop('label', axis=1))\n",
    "y_train = np.array(train['label'])\n",
    "\n",
    "# normalize pixel values\n",
    "X_train = np.multiply(X_train, 1.0 / 255.0)\n",
    "\n",
    "# function to convert labels to one-hot vectors\n",
    "def dense_to_one_hot(labels_dense):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * 10\n",
    "    labels_one_hot = np.zeros((num_labels, 10))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "# use the function!\n",
    "y_train = dense_to_one_hot(y_train).astype(np.int)\n",
    "\n",
    "# split into training / validation sets (let's use a 37,000 / 5,000 split)\n",
    "X_train, X_valid = X_train[:TRAIN_SIZE], X_train[TRAIN_SIZE:]\n",
    "y_train, y_valid = y_train[:TRAIN_SIZE], y_train[TRAIN_SIZE:]\n",
    "\n",
    "# get shapes of training, validation, and test datasets\n",
    "print 'training data shapes:', X_train.shape, y_train.shape\n",
    "print 'validation data shapes:', X_valid.shape, y_valid.shape\n",
    "print 'test data shape:', X_test.shape\n",
    "\n",
    "# get size, shape of dataset images\n",
    "image_size = X_train[0,:].shape[0]\n",
    "print 'image size:', image_size\n",
    "image_side_length = int(np.sqrt(X_train[0,:].shape[0]))\n",
    "print 'image shape:', image_side_length, 'x', image_side_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Digit Images\n",
    "\n",
    "A simple function (borrowed from https://www.kaggle.com/kakauandme/digit-recognizer/tensorflow-deep-nn) to display a digit image. We need to reshape from (784,) to (28, 28) so we have the correct _human friendly_ representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display image\n",
    "def display(img):    \n",
    "    # (784) => (28,28)\n",
    "    img = img.reshape((28,28))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=cm.binary)\n",
    "\n",
    "# output image     \n",
    "display(choice(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Tensorflow Computation Graph\n",
    "\n",
    "Tensorflow does much of its numerical computation and book-keeping outside of Python. Tensorflow allows us to build an entire graph of interacting operations, and run the whole workflow in a separate process all at once.\n",
    "\n",
    "I define several helper functions for creating weight / bias variables and convolution and pooling operations.\n",
    "\n",
    "Since we're using ReLUs (rectified linear units, defined by $f(x) = max(0, x)$), we initialize weight vectors with a bit of positive noise to avoid \"dead neurons\"; i.e., units whose activations fall below zero and never becoem positive again.\n",
    "\n",
    "We'll use zero-padded convolutions so that the output is the same size as the input. The convolution stride in this case is 1 (subject to change). Generally, convolutional layers are responsible for extracting different levels of features from the input data or the output from a previous layer. In digit recognition, low-level features might consist of (among other things) edges (black to white) of various orientation, and higher-level features might consist of sub-shapes characteristic of certain digits, or even canonical or averaged representations of an entire digit class.\n",
    "\n",
    "We use max-pooling over 2x2 blocks (subject to change). This operation is used to down-sample, or reduce the dimensionality of, the output of a previous layer. Max-pooling keeps only the maximum value from each (2x2) block of its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# bias initialization\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# convolution operation\n",
    "def conv2d(x, W):\n",
    "    # using TensorFlow's conv2d operation with above mentioned parameters\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# max-pooling operation\n",
    "def max_pool_2x2(x):\n",
    "    # using TensorFlow's max_pool operation\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any neural network can be used as a layer in a larger neural network (since a \"layer\" need only be a differentiable operation; this holds for entire NNs). This means that the output for one network can be used as the input for another network. This compositional approach to building neural networks is the reason for the now-popular moniker \"deep learning\".\n",
    "\n",
    "In this notebook, we'll implement a convolutional neural network with two convolutional layers and two max-pooling layers interweaved, a fully-connected layer, and then a logistic regression layer trained on the activations output from the fully-connected layer.\n",
    "\n",
    "Let's define variables for NN input, output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', shape=[None, image_size])\n",
    "y_ = tf.placeholder('float', shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer is a convolution layer followed by max-pooling. The convolution computes 32 features for each 5x5 in the image (with strides of 1). Thus, its weights tensor has shape [5, 5, 1, 32], where the first two dimensions are patch size, the second is the number of input channels (1 corresponds to the fact that the image is grayscale), and the last is the number of output channels or filters. There is also a bias vector with a single component for each output channel.\n",
    "\n",
    "To apply the layer, we reshape the input data into a 4-dimensional tensor with the first dimension corresponding to the number of images, the second and third to the image width and height, and the last to the number of input channels (On the image input, its shape becomes [37,000, 28, 28, 1]).\n",
    "\n",
    "After the convolution operation, the max-pooling operation reduces the size of the output (of each channel) from 28x28 to 14x1 (of which there are 32, for an output tensor of shape [37,000, 14, 14, 32])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1st convolution layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# reshaping input (-1 corresponds to arbitrary dimensionality)\n",
    "image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "# print image.get_shape() gives (?, 28, 28, 1)\n",
    "\n",
    "# convolution hidden layer\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1)\n",
    "\n",
    "# max-pooling hidden layer\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Prepare for visualization\n",
    "# display 32 features in a (4 x 8) grid\n",
    "layer1 = tf.reshape(h_conv1, (-1, 28, 28, 4, 8))  \n",
    "\n",
    "# reorder so the channels are in the first dimension, x and y follow.\n",
    "layer1 = tf.transpose(layer1, (0, 3, 1, 4,2))\n",
    "layer1 = tf.reshape(layer1, (-1, 28*4, 28*8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer has 64 features for each 5x5 input patch (again, strided by 1). Therefore, its weight tensor has shape [5, 5, 32, 64], where the first two dimensions are patch size, the third is the number of input channels, and the fourth is the number of output channels. Again, there is a bias vector which has a single component for each output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2nd convolution layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# convolution hidden layer\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "# max-pooling hidden layer\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Prepare for visualization\n",
    "# display 64 features in a (4 x 16) grid\n",
    "layer2 = tf.reshape(h_conv2, (-1, 14, 14, 4 ,16))  \n",
    "\n",
    "# reorder so the channels are in the first dimension, x and y follow.\n",
    "layer2 = tf.transpose(layer2, (0, 3, 1, 4,2))\n",
    "\n",
    "layer2 = tf.reshape(layer2, (-1, 14*4, 14*16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image size has been reduced to 7x7 by the last max-pooling layer, and so the shape of the data tensor is now [37,000, 7, 7, 64]. Now, we add a fully-connected layer of 1,024 neurons to do processing on the entire current feature representation of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully-connected layer\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# flattening output of previous max-pooling layer\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "# fully-connected hidden layer\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply dropout before the read-out layer in an effort to prevent over-fitting to training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder('float')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we attach a logisic regression layer to the output of the previous fully-connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# readout layer / softmax\n",
    "W_out = weight_variable([1024, 10])\n",
    "b_out = bias_variable([10])\n",
    "\n",
    "# output (softmax)\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_out) + b_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the cross-entropy loss to evaluate network performance, and use the ADAM optimizer to minimize this loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "\n",
    "# optimization function\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "# evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict values from test data, the highest probability will be picked from the one-hot vector representation, indicating the relative chances of an image being one of each of the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction function\n",
    "predict = tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validate, and Predict\n",
    "\n",
    "Now that we've defined our neural network architecture, we can train and validate our model, and compile a prediction file for the Kaggle competition.\n",
    "\n",
    "I define a helper function for doing mini-batch-wise training (stochastic mini-batch training), which is cheaper, faster, and gives similar results than using the entire training dataset per step of network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "# serve up data by minibatch\n",
    "def next_batch():\n",
    "    batch_size = BATCH_SIZE\n",
    "    \n",
    "    global X_train\n",
    "    global y_train\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all training data have been already used, reorder it randomly   \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return X_train[start:end], y_train[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when all operations for every variable is defined in the TensorFlow graph, all computations will be performed outside the Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start TensorFlow session\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each step of the loop, we get a minibatch of training data, which we feed into the computation graph to replace the placeholders \"x\", \"y\\_\", and \"dropout\". We check training / validation set accuracy every once in a while on an incoming minibatch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualization variables\n",
    "train_accuracies, validation_accuracies, X_range = [], [], []\n",
    "display_step = 1\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # get a new training minibatch\n",
    "    X_batch, y_batch = next_batch()\n",
    "        \n",
    "    # check progress on certain epochs\n",
    "    if i % display_step == 0 or (i + 1) == EPOCHS:\n",
    "        # get training accuracy on incoming minibatch\n",
    "        training_accuracy = accuracy.eval(feed_dict={x : X_batch, y_ : y_batch, keep_prob : 1.0})\n",
    "        \n",
    "        # get validation accuracy on incoming minibatch\n",
    "        validation_accuracy = accuracy.eval(feed_dict={x : X_valid[0:BATCH_SIZE], y_ : y_valid[0:BATCH_SIZE], keep_prob : 1.0})\n",
    "        \n",
    "        print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(training_accuracy, validation_accuracy, i))\n",
    "            \n",
    "        validation_accuracies.append(validation_accuracy)\n",
    "        \n",
    "        train_accuracies.append(training_accuracy)\n",
    "        X_range.append(i)\n",
    "        \n",
    "        # increase display step\n",
    "        if i % (display_step*10) == 0 and i:\n",
    "            display_step *= 10\n",
    "            \n",
    "    # train on minibatch\n",
    "    sess.run(train_step, feed_dict={x : X_batch, y_ : y_batch, keep_prob: DROPOUT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check final accuracy on validation set  \n",
    "\n",
    "validation_accuracy = accuracy.eval(feed_dict={x : X_valid, y_ : y_valid, keep_prob: 1.0})\n",
    "\n",
    "print 'validation_accuracy => %.4f' % validation_accuracy\n",
    "\n",
    "plt.plot(X_range, train_accuracies,'-b', label='Training')\n",
    "plt.plot(X_range, validation_accuracies,'-g', label='Validation')\n",
    "\n",
    "plt.legend(loc='lower right', frameon=False)\n",
    "plt.ylim(ymax = 1.1, ymin = 0.7)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're happy with the output, we can predict the labels for the test dataset. The test data contains only images and no labels; otherwise, its structure is identical to the training dataset. Predicted labels will be stored in a .csv file for submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read test data from CSV file \n",
    "X_test = pd.read_csv('../data/test.csv').values\n",
    "X_test = X_test.astype(np.float)\n",
    "\n",
    "print 'test data shape:', X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert from [0:255] => [0.0:1.0]\n",
    "X_test = np.multiply(X_test, 1.0 / 255.0)\n",
    "\n",
    "# predict the labels of the test dataset. using minibatches is more resource efficient\n",
    "predicted_labels = np.zeros(X_test.shape[0])\n",
    "for i in range(X_test.shape[0] // BATCH_SIZE):\n",
    "    predicted_labels[i * BATCH_SIZE:(i+1) * BATCH_SIZE] = predict.eval(feed_dict={x : X_test[i * BATCH_SIZE : (i + 1) * BATCH_SIZE], keep_prob: 1.0})\n",
    "    \n",
    "print 'predicted labels shape:', len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output random test image and prediction\n",
    "random_idx = choice(range(len(X_test)))\n",
    "random_img = X_test[random_idx]\n",
    "display(random_img)\n",
    "\n",
    "print 'predicted_labels[{0}] => {1}'.format(random_idx, predicted_labels[random_idx])\n",
    "\n",
    "# save results of test dataset prediction\n",
    "np.savetxt('../submissions/submission_15000_epochs.csv', np.c_[range(1, len(X_test) + 1), predicted_labels], delimiter=',', header='ImageId,Label', comments='', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
